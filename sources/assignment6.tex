\documentclass[assignments]{subfiles}


\begin{document}


\section{Assignment 6, TBD}


\subsection{Have you read well?}

\subsection{Exercises at about exam level}
\label{sec:exercises-at-about-1}



\begin{exercise}
Here is (what I find) a simpler proof of the Cauchy-Schwartz inequality.  Define  $f(t) = \E{(Y-tX)^2}$.
\begin{enumerate}
\item Explain that $f(t)\geq 0$.
\item Write $f(t) = \E{(Y-tX)^2}$ as a polynomial of the second degree, i.e., in the form $f(t) = a t^2 + b t + c$ (Hint, see BH).
\item Since $f(t) \geq 0$, how many (real) roots can it have at most?
\item What are the implications of this for the discriminant $D=b^2-4ac$?
\item Show that the Cauchy-Schwartz inequality directly follows from this restriction on $D$.
\end{enumerate}
\end{exercise}

\begin{exercise}
Here is inequality from which all inequalities in BH 10.1.3 immediately follow. It's worth memorizing.
Take any r.v. $X$ and a function $f$ that is non-negative and non-decreasing.
\begin{enumerate}
\item Why is this true for any $a$: $f(a) \1{X\geq a} \leq f(X) \1{X\geq a} \leq f(X)$?
\item Take expectations in the inequality of the previous step and use the fundamental bridge to show that $\P{X\geq a} \leq \E{f(X)}/f(a)$.
\item What part of the proof goes wrong if  $f$ can also be negative?
\item Show that Markov's inequality follows by taking $Y=|X|$ and  $f(x)=x$. Why don't we take $f(x) = |x|$?
\item Show that Chebyshev's inequality follows by taking $Y=|X-\mu|$ and $f(x)=x^2$.
\item Show that Chernoff's inequality follows by taking $f(x)=e^{x}$.
\end{enumerate}
\end{exercise}



\subsection{Coding skills}

\paragraph{Let us try to understand} the weak law of large numbers by means of simulation. An easy example is to take $X_{i}\sim\Unif{0,1}$, so that is what we do here.

\begin{minted}[]{python}
import numpy as np
from numpy.random import uniform

np.random.seed(3)

n = 10
N = 50 # num samples

mu = 1 / 2
var = 1 / 12
eps = 0.1

X = uniform(size=[num_samples, n])

Y = X.mean(axis=1)

larger = np.abs(Y - mu) > eps
count = larger.sum()
P = count / N
RHS = var / (n * eps * eps)
print(P, RHS)
\end{minted}

\begin{exercise}
Explain lines 9 and 10 of the python code.
\begin{solution}
\end{solution}
\end{exercise}

\begin{exercise}
What is \texttt{Y}, i.e., the result of line 15 of the python code? What is the symbol that BH use for this?
\begin{solution}
\end{solution}
\end{exercise}

\begin{exercise}
What do lines P.17 and P.18 compute?
\begin{solution}
\end{solution}
\end{exercise}

\begin{exercise}
What is P.20 in the notation of BH?
\begin{solution}
\end{solution}
\end{exercise}

\begin{exercise}
What inequality do we check in P.21?
\begin{solution}
\end{solution}
\end{exercise}

\begin{exercise}
Choose some different values for $n$ and the sample size $N$. Is the inequality always true?
\begin{solution}
\end{solution}
\end{exercise}

\paragraph{Htting times} BH.10.39.a asks about the first time such that some exponential r.v.
exceeds a certain threshold.
Part b is about when the sum of a number of r.v.s exceed a threshold.
Such problems are called \emph{hitting times}.

\begin{minted}{python}
import numpy as np
from scipy.stats import expon

np.random.seed(3)

X = expon(scale=1)

# part a

N = 10
res = np.zeros(N)
for i in range(N):
    n = 0
    while X.rvs() < 1:
        n += 1
    res[i] = n

print(res.mean(), res.std())

# part b

N = 100
res = np.zeros(N)
for i in range(N):
    M = X.rvs()
    n = 1
    while M < 10:
        M += X.rvs()
        n += 1
    res[i] = n

print(res.mean(), res.std())
\end{minted}

By now you have so much experience with reading code that you must be able to explain all without intermediate steps to guide you.
\begin{exercise}
Explain why the first part of the code simulates BH.10.39.a.
\begin{solution}
\end{solution}
\end{exercise}

\begin{exercise}
Explain why the second part of the code simulates BH.10.39.b
\begin{solution}
\end{solution}
\end{exercise}



\end{document}
