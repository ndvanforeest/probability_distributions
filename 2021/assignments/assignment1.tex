% arara: pdflatex: { shell: yes }
% arara: pythontex: {verbose: yes, rerun: modified }
% arara: pdflatex: { shell: yes }

\documentclass[assignments]{subfiles}

\begin{document}


\section{Assignment 1}
\label{sec:org9cbca82}


\subsection{Have you read well?}
\label{sec:have-you-read}


\begin{exercise}
In your own words, explain what is
\begin{enumerate}
\item a joint PMF, PDF, CDF;
\item a conditional PMF, PDF, CDF;
\item a marginal PMF, PDF, CDF.
\end{enumerate}
\begin{solution}
Check the definitions of the book.

Mistake: To say that $\P{X=x}$ is the PMF for a continuous random variable is wrong, because $\P{X=x}=0$ when $X$ is continuous.

Why is $\P{1 < x \leq 4}$ wrong notation?
hint: $X$ should be a capital.
What is the difference between $X$ and $x$?

\end{solution}
\end{exercise}

\begin{exercise}
We have two r.v.s $X, Y \in [0,1]^{2}$ (here $[0,1]^{2} = [0,1]\times [0,1]$) with the joint PDF $f_{X,Y}(x,y) = 2 \1{x\leq y}$.
\begin{enumerate}
\item Are $X$ and $Y$ independent?
\item Compute $F_{X,Y}(x,y)$.
\end{enumerate}
\begin{solution}
\begin{align}
f_{X}(x) &= \int_{0}^{1} f_{X,Y}(x,y) \d y = 2\int_{0}^{1} \1{x\leq y} \d y = 2\int_{x}^{1} \d y = 2(1-x) \\
f_{Y}(y) &= \int_{0}^{1} f_{X,Y}(x,y) \d x = 2\int_{0}^{1} \1{x\leq y} \d x = 2\int_{0}^{y} \d y = 2 y.
\end{align}
But $f_{X,Y}(x,y) \neq f_{X}(x)f_{Y}(y)$, hence $X,Y$ are dependent.

\begin{align}
F_{X,Y}(x,y)
&= \int_{0}^{x}\int_{0}^{y} f_{X,Y}(u,v) \d v \d u \\
&= 2\int_{0}^{x}\int_{0}^{y} \1{u\leq v} \d v \d u \\
&= 2\int_{0}^{x}\int \1{u\leq v} \1{0\leq v \leq y}\d v \d u \\
&= 2\int_{0}^{x}\int  \1{u\leq v \leq y}\d v \d u \\
&= 2\int_{0}^{x} [y-u]^{+} \d u,
\end{align}
because $u\geq y \implies \1{u\leq v \leq y} = 0$. Now, if $y>x$,
\begin{align}
  2\int_{0}^{x} [y-u]^{+} \d u &=
  2\int_{0}^{x} (y-u) \d u = 2 y x - x^{2},
\end{align}
while if $y\leq x$,
\begin{align}
  2\int_{0}^{x} [y-u]^{+} \d u &=
  2\int_{0}^{y} (y-u) \d u = 2 y^{2} - y^{2} = y^{2}
\end{align}

Make a drawing of the support of $f_{X,Y}$ to help to understand this better.

\end{solution}
\end{exercise}

\begin{exercise}
Correct (that is, is the following claim correct?)?
We have two continuous r.v.s $X, Y$.
Even though the joint CDF factors into the product of the marginals, i.e., $F_{X,Y}(x,y) = F_X(x)F_Y(y)$, it is still possible in general that the joint PDF does not factor into a product of marginals PDFs of $X$ and $Y$, i.e., $f_{X,Y}(x,y) \neq f_X(x) f_Y(y)$.
\begin{solution}
\begin{align*}
\partial_{x}\partial_{y}F_{X,Y}(x,y)
=\partial_{x}\partial_{y}F_{X}(x) F_{Y}(y)
=\partial_{x}F_{X}(x) \partial_{y} F_{Y}(y) = f_{X}(x) f_{Y}(y).
\end{align*}
\end{solution}
\end{exercise}

\begin{exercise}
Consider $F_{X,Y}(x,y)/F_{X}(x)$. Write this expression as a conditional probability. Is this equal to the conditional CDF of $X$ and $Y$?
\begin{solution}

\begin{align}
  \label{}
\frac{F_{X,Y}(x,y)}{F_{X}(x)} = \frac{\P{X\leq x, Y\leq y}}{\P{X\leq x}}
\end{align}
In the notes we define the conditional CDF as the function $F_{X|Y}(x|y) = \P{X\leq x | Y=y}$. This is not the same as the function above.


Mistake: $F_{X,Y}(x,y) \neq \P{X=x, Y=y}$. If you wrote this, recheck BH.
for the conditional CDF, you do not condition on e.g. $X\leq x$.
Compare your answer to what is written in the notes or the solution manual. Good notation and good understanding are positively correlated :).
\end{solution}
\end{exercise}

\begin{exercise}
Let $X$ be uniformly distributed on the set $\{0,1,2\}$ and let $Y \sim \Bern{1/4}$; $X$ and $Y$ are independent.
\begin{enumerate}
\item Present a contingency table for the $X$ and $Y$.
\item What is the interpretation of the column sums the table?
\item What is the interpretation of the row sums of the table?
\item Suppose you change some of the entries in the table. Are $X$ and $Y$ still independent?
\end{enumerate}
\begin{solution}
$\P{X=0, Y=0} = 1/3 \cdot 3/4$,
$\P{X=0, Y=1} = 1/3 \cdot 1/4$, and so on.

If we have one column with $Y=0$ and the other with $Y=1$, then the sum over the columns are $\P{Y=0}$ and $\P{Y=1}$. The row sum for row $i$ are  $\P{X=i}$.

Changing the values will (most of the time) make $X$ and $Y$ dependent. But, what if we changes the values such that  $\P{X=0, Y=0} =1$? Are $X$ and $Y$ then again independent? Check the conditions again.
\end{solution}
\end{exercise}

\begin{exercise}
Apply the chicken-egg story.
A machine makes items on a day.
Some items, independent of the other items, are failed (i.e., do not meet the quality requirements).
What is $N$, what is $p$, what are the `eggs' in this context, and what is the meaning of `hatching'?
What type of `hatching' do we have here?
\begin{solution}
  The number of produced items (laid eggs) is $N$. The probability of hatching is $p$, that is, an item is ok. The hatched eggs are the good items.
\end{solution}
\end{exercise}

% \begin{exercise}
% Apply the chicken-egg story. Families enter a zoo in a given hour. Some families have one child, other two, and so on.
% What are the `eggs' in this context, and what is the meaning of `hatching'?
% \end{exercise}


\begin{exercise}
Correct? We have two r.v.s $X$ and $Y$ on $\R^{+}$. It is given that $F_{X,Y}(x,y) = F_X(x)F_Y(y)$ for $x,y \leq 1/3$. Then  $X$ and $Y$ are necessarily independent.
\begin{solution}
For $X, Y$ to be independent, it is necessary that  $F_{X,Y}(x,y) = F_X(x)F_Y(y)$ for all $x,y$, not just one particular choice. (This is an example that satisfying a necessary condition is not necessarily sufficient.)
\end{solution}
\end{exercise}

\begin{exercise}
I select a random guy from the street, his height $X\sim\Norm{1.8, 0.1}$, and I select a random woman from the street, her height is $Y\sim\Norm{1.7, 0.08}$.
I claim that since I selected the man and the woman independently, their heights are independent.
Briefly comment on this claim.
\begin{hint}
From this exercise you should memorize this: \textbf{independence is a property of the joint CDF, not of the rvs}.
\end{hint}
\begin{solution}
  Many answers are possible here, depending on extra assumptions you make.
  Here is one.
  Suppose, just by change, the fraction of taller guys in the street is a bit higher the population fraction.
  Assuming that taller (shorter) people prefer taller (shorter) spouses, there must be dependence between the height of the men and the woman. This is because when selecting a man, I can also select his wife.

Mistake:   $\P{Y}$ is wrong notation. This is wrong because we can only compute the probability of an event, such as $\{Y\leq y\}$. But $Y$ itself is not an event.
\end{solution}
\end{exercise}


\begin{exercise}
Correct? For any two r.v.s $X$ and $Y$ on $\R^{+}$ with marginals $F_{X}$ and $F_{Y}$, it holds that $\P{X\leq x, Y\leq y} = F_{X}(x) F_{Y}(y)$.
\begin{solution}
Only when $X, Y$ are independent.

Mistake:  independence of $X$ and $Y$ is not the same as the linear independence. Don't confuse these two types of dependene.
\end{solution}

\end{exercise}

\begin{exercise}
Theorem 7.1.11. What is the meaning of the notation $X|N=n$?
\begin{solution}
  Given $N=n$, the random variable $X$ has a certain distribution, binomial for instance.
\end{solution}
\end{exercise}

\begin{exercise}
Correct? $X, Y$ are two discrete r.v.s with CDF $F_{X,Y}$. We can compute the PDF as $\partial_{x}\partial_{y} F_{X,Y}(x,y)$.
\begin{solution}
This claim is incorrect, because $X, Y$ are discrete, hence they have a PMF, not a PDF.

Mistake: Someone said that $\partial_{x}\partial_{y}$ is not correct notation; however, it is correct! It's a (much used) abbreviation of the much heaver $\partial^{2}/\partial x \partial y$. Next, the derivative of the PMF is not well-defined (at least, not within this course. If you object, ok, but then show that you passed a decent course on measure theory.)
\end{solution}
\end{exercise}


\subsection{Exercise at about exam level}
\label{sec:below-exam-level}



\begin{exercise}
This is about the simplest model for an insurance company that I can think of.
We start with an initial capital $I_0=2$.
The company receives claims and contributions every period, a week say.
In the $i$th period, we receive a contribution $X_{i}$ uniform on the set $\{1, 2,\ldots,10\}$ and a claim $C_i$ uniform on $\{0, 1, \ldots 8\}$.
\begin{enumerate}
\item What is the meaning of $I_1=I_0+X_1-C_1$?
\item What is the meaning of $I_2=I_1+X_2-C_2$?
\item What is the interpretation of $I_1'=\max\{I_0-C_1,0\} + X_1$?
\item What is the interpretation of $I_2'=\max\{I_1'-C_2,0\} + X_2$?
\item What is the interpretation of $\bar I_{n} = \min\{I_{i} : 0\leq i\leq n\}$?
\item What is  $\P{I_1 < 0}$?
\item What is  $\P{I_1' < 0}$?
\item What is  $\P{I_2 < 0}$?
\item What is  $\P{I_2' < 0}$?
\item Provide an interpretation in terms of the inventory of rice, say, at a supermarket for $I_{1}$ and $I_{1}'$.
\end{enumerate}
\begin{solution}
This question tests your modeling skills too.

In hindsight, the questions have to reorganized a bit.
The capital at the end of the $i$th week is $I_{i} = I_{i-1} + X_{i} - C_{i}$.

Suppose claims arrive at the beginning of the week, and contributions arrive at the end of the week (people prefer to send in their claims early, but they prefer to pay their contribution as late as possible).
If we don't have sufficient money in cash, then we cannot pay a claim.
Thus, $\max\{I_{0}-C_{1}\}$ is our capital just before the contribution arrives. Hence, $I_{1}'$ is our capital at the end of week 1 under the assumption that we never pay out more than we have in cash. Likewise for $I_{2}'$

$\bar I_{n}$ is the lowest capital we have seen for the first $n$ weeks.

In the supermarket setting, $I_{i}$ is our inventory is we can be temporarily out of stock, but as soon as new deliveries---so called replenishments---arrive then we serve the waiting customers immediately.
The model with $I'$ corresponds to a setting is which we consider unmet demand as lost.

\begin{align}
  \label{}
\P{I_{0} < = 0} &= \P{2 + X_{1} - C_{1} < 0} = \frac{1}{10} \sum_{i=1}^{10} \P{C_{1} > 2 + i } = \frac{1}{10} \sum_{i=1}^{5} \P{C_{1} > 2 + i } \\
&= \frac{1}{10} \sum_{i=1}^{5} \frac{6-i}{9}.
\end{align}

When grading, I realized that questions 8 was not quite reasonable to ask as an exam question.
We graded this leniently.
As I find it too boring to compute these probabilities by hand, here is the python code.
The ideas in the code are highly interesting and useful.
The main data structure here is a dictionary, one of the most used data structure in python.
I don't have the R code yet, so if you take the (unwise) decision to stick to only R, you have to wait a bit until somebody sends me the R code for this problem.
\begin{minted}{python}
C = {}
for i in range(0, 9):
    C[i] = 1 / 9

X = {}
for i in range(1, 11):
    X[i] = 1 / 10


I0 = 2

I1 = {}
for k, p in X.items():
    for l, q in C.items():
        i = I0 + k - l
        I1[i] = I1.get(i, 0) + p * q

print("I1, ", sum(I1.values()))  # check


# compute P(I1<0):
P = sum(r for i, r in I1.items() if i < 0)
print(P)


I2 = {}
for i, r in I1.items():
    for k, p in X.items():
        for l, q in C.items():
            j = i + k - l
            I2[j] = I2.get(j, 0) + r * p * q

print("I2 ", sum(I2.values()))  # just a check

# compute P(I2<0):
P = sum(r for i, r in I2.items() if i < 0)
\end{minted}

Interestingly, $I_{i}'\geq 1$. (This is so simple to see that I first did it wrong.)



Mistake: note that $X_{i}$   and $C_{i}$ are discrete r.v.s, not continuous.
The sum of two uniform random variables is not uniform. For example, think of the sum of two die throws. Is getting 2 just as likely as getting 7?
\end{solution}


\end{exercise}

\subsection{Coding skills}
\label{sec:coding-skills}



\begin{exercise}
Use simulation to estimate the answer of BH.7.1. Run the code below and explain line 9 of python code or line 7 of the R code.


Then run the code for a larger sample, e.g, \verb|num=1000| or so, but remove the prints of \verb|a|, \verb|b|, and \verb|succes|, because that will fill your screen with numbers you don't need.
Only for small simulations such output is handy so that you can check the code.

Compare the value of the simulation to the exact value.


\begin{minted}[]{python}
import numpy as np

np.random.seed(3)

num = 10

a = np.random.uniform(size=num)
b = np.random.uniform(size=num)
success = np.abs(a - b) < 0.25
print(a)
print(b)
print(success)
print(success.mean(), success.var())
\end{minted}


\begin{minted}[]{R}
set.seed(3)

num <- 10

a <- runif(num)
b <- runif(num)
success <- abs(a-b) < 0.25
a
b
success
paste(mean(success), var(success))
\end{minted}

Challenge (not obligatory): If you like, you can include a plot of the region (in time) in which Alice and Bob meet, and put marks on the points of the simulation that were `successful'.


\end{exercise}



\begin{exercise}
Let $X\sim\Exp{3}$.
Find a simple expression for $\P{1 < X \leq 4}$ and compute the value.
Then use simulation to check this value.
Finally, use numerical integration to compute this value. What are the numbers? Explain lines 11, 21 and 26 of the python code or lines 7, 17 and 23 of the R code.

\begin{minted}[]{python}
import numpy as np
from scipy.stats import expon
from scipy.integrate import quad

labda = 3

X = expon(scale = 1 / labda).rvs(1000)
# print(X)
print(X.mean())

success = (X > 1) * (X < 4)
# print(success)
print(success.mean(), success.std())


def F(x):  # CDF
    return 1 - np.exp(-labda * x)


def f(x):  # density
    return labda * np.exp(-labda * x)


print(F(4) - F(1))

I = quad(f, 1, 4)
print(I)
\end{minted}



\begin{minted}[]{R}
labda <- 3

X <- rexp(1000, rate = labda)
# X
mean(X)

success <- (X > 1) * (X < 4)
# print(success)
paste(mean(success), sd(success))


CDF <- function(x) {  # CDF
  return(1 - exp(-labda * x))
}

f <- function(x) {    # density
  return(labda * exp(-labda * x))
}


CDF(4) - CDF(1)

I = integrate(f, 1, 4)
I
\end{minted}
\begin{solution}
Mistakes: Simulation and numerical integration are not the same.
Formulate your answers precisely: it is not simulation that yields exactly the same value!
\end{solution}

\end{exercise}


\subsection{Challenges, optional}
\label{sec:above-exam-level}

You are free to chose one of these problems, but of course you can do both if you like.

\paragraph{A uniqueness property of the Poisson distribution}

Consider again the chicken-egg story (BH 7.1.9): A chicken lays a random number of eggs $N$ an each egg independently hatches with probability $p$ and fails to hatch with probability $q = 1-p$.
Formally, $X|N\sim\Bin{N,p}$.
Assume also that $X|N\sim\Bin{N,p}$ and that $N-X$ is independent of $X$.
For $N \sim \Pois{\lambda}$ it is shown in BH 7.1.9 that $X$ and $Y$ are independent.
This exercise asks for the converse: showing that the independence of $X$ and $Y$ implies that $N \sim \Pois{\lambda}$ for some $\lambda$.
Hence, the Poisson distribution is quite special: it is the only distribution for which the number of hatched eggs doesn't tell you anything about the number of unhatched eggs.

Let $0 < p < 1$. Let $N$ be an r.v. taking non-negative integer values with $P(N > 0) > 0$.
Assume also that  $X|N\sim\Bin{N,p}$ and that $N-X$ is independent of $X$.

\begin{exercise}
 Use the assumption that $\P{N>0}>0$ to prove that $N$ has support $\mathbb N$, i.e. $\P{N=n} > 0$ for all $n \in \mathbb N$. Note: $0 \in \mathbb N$.
\begin{hint}
In this exercise we want to prove that $N$ is Poisson distributed. So you cannot assume this in your solution.
\end{hint}
\end{exercise}

\begin{exercise}
Write $Y = N-X$. Prove that
\begin{equation}
\label{eq:1}
\P{X=x}\P{Y=y} = {x+y \choose x} p^x (1-p)^y \P{N=x+y}.
\end{equation}
\end{exercise}


\begin{exercise}
Prove that $N$ is Poisson distributed.
\begin{hint}

Use the relation of the previous exercise to show that
\begin{equation}
  \label{eq:3}
P(N=n+1) = \frac{\lambda}{1+n} P(N=n).
\end{equation}
\textit{Bigger hint:} Fill in $y=0$ in the LHS and RHS of~\cref{eq:1}; call this expression 1. Then fill in $y=1$ to a obtain a second expression. Divide these two expressions and note that $\P{X=x}$ cancels. Finally,  define
\begin{equation}
\label{eq:2}
\lambda = \frac{\P{Y=1}}{(1-p)\P{Y=0}}.
\end{equation}
\end{hint}
\opt{check}{
\begin{solution}
\textit{Solution part 1.}  We first prove that $N$ is not bounded. For the sake of contradiction, let $n\in \mathbb N$ be the smallest $n$ such that $P(N \leq n) = 1$. Then $P(N=n) > 0$ and hence also $P(X=n) > 0$, but $X=n$ implies $N=n$ and hence $N-X=0$. So $$P(N-X=0|X=n) = 1.$$
On the other hand, $P(N-X=0|X=0) = 1 - P(N-X>0|X=0) =  1- P(N>0|X=0) < 1$, which violates the independence of $N-X$ and $X$.

Now we prove that $P(N=n) > 0$ for all $n \in \mathbb N$. \\
Assume the contrary and let $n\in \mathbb N$ be such that $P(N=n) = 0$.
Then $$P(N-X=0|X=n) = P(N=n|X=n) = 0.$$
On the other hand, since $N$ is not bounded there is an $m > n$ with $P(N=m)>0$ and hence also $P(X=m)>0$. Then, by Bayes' rule: $$P(N-X=0|X=m) = P(N=m|X=m) = \frac{P(X=m|N=m)P(N=m)}{P(X=m)} > 0,$$
again a violation of the independence of $N-X$ and $X$.


\textit{Solution part 2.}
Write $Y = N-X$. The independence of $X$ and $Y$ implies that $$P(X=x)P(Y=y) = P(X=x, Y=y).$$
We also want to use the distribution of $X$ conditional on $N$:
$$P(X=x, Y=y) = P(X=x, Y=y|N=x+y)P(N=x+y).$$
Note that $$P(X=x, Y=y|N=x+y) = P(X=x|N=x+y) = \binom{x+y}{x} p^x (1-p)^y,$$
since $X=x$ already implies $Y=y$, and using that  $X|N\sim\Bin(N,p)$.

Combining all of this, we obtain:
 $$P(X=x)P(Y=y) = \binom{x+y}{x} p^x (1-p)^y P(N=x+y).$$


 \textit{Solution part 3.}
 Plugging in $y=0$ yields $P(X=x)P(Y=0) = p^x P(N=x)$. \\
 Plugging in $y=1$ yields $P(X=x)P(Y=1) = (x+1)p^x (1-p) P(N=x+1)$. \\
 Dividing the second expression by the first implies $$\frac{P(Y=1)}{P(Y=0)} =  (x+1)(1-p) \frac{P(N=x+1)}{P(N=x)}.$$
 Let $\lambda = \dfrac{P(Y=1)}{(1-p)  P(Y=0)} $. Note that $1-p > 0$ and $P(Y=0) > 0$, as shown earlier.


 Then this equation implies $P(N=x+1) = \dfrac{\lambda}{(x+1)} P(N=x)$. By induction it follows that $$P(N = n) = \frac{\lambda^n}{n!} P(N=0).$$
 Now summing yields $$1 = \sum_{n=0}^\infty P(N=n) = \sum_{n=0}^\infty \frac{\lambda^n}{n!} P(N = 0) = e^{\lambda} P(N=0),$$
and hence we conclude that
$$P(N = n) = \frac{e^{-\lambda}\lambda^n}{n!},$$
so $N \sim \Pois(\lambda)$.
\end{solution}
}
\end{exercise}



\paragraph{Improper integrals and the Cauchy distribution}

This problem challenges your integration skills and lets you think about the subtleties of integrating a function over an infinite domain.
(Such integrals are called improper integrals.)

Assume that $X$ has the Cauchy distribution.
Recall that $\E{X}$ does not exist (hence, it is not automatic that the expectation of a some arbitrary r.v.
exists).
\begin{exercise}
Why does $\E{\frac{|X|}{X^2+1}}$ exist? Find its value. It is essential that you include your arguments.
\end{exercise}


\begin{exercise}
Explain why the previous exercise implies that $\E{\frac{X}{X^2+1}}$ exists. Then find its value.
\end{exercise}


\end{document}

\subsection{TODO for another year}

Here are some ideas for another time. You can neglect this.



\begin{exercise}\label{ex:1}
We throw an unbiased die with six sides; the result of the $i$th throw is $X_i$.
\begin{enumerate}
\item What is the sample space of the two throws $(X_{1}, X_2)$?
\item What is the joint CDF?
\item What is the joint PMF?
\item  Marginalize out $X_2$ to show that $\P{X_1=5} = 1/6$.
\item Use the fundamental bridge and indicators to compute $\P{X_1>X_2}$.
\item Use the fundamental bridge and indicators to compute $\P{|X_1-X_2| < 1 } = 1/6$.
\item Use the fundamental bridge and indicators to compute $\P{|X_1-X_2|\leq 1 }$.
\item How would you use simulation to estimate  $\P{|X_1-X_2|\leq 1 }$?
\end{enumerate}
\end{exercise}

\begin{exercise}
We select a random married couple (a man and a woman). His height is $X\sim \Norm{1.8, 0.1}$, her height is $Y\sim \Norm{1.7, 0.08}$ in meters.
\begin{enumerate}
\item What is the sample space of $(X, Y)$?
\item If your answer to question 1 is correct, you must have noticed that potentially the height of the man and the woman can be negative. Is this a problem for this model?
\item What is the joint CDF?
\item What is the joint PDF?
\item  Marginalize out $Y$ to show that $X\sim \Norm{1.8, 0.1}$.
\item Use the fundamental bridge and indicators to write  $\P{X>Y}$ as an integral. You don't have to solve the integral.
\item Use the fundamental bridge and indicators to write  $\P{|X-Y| < 0.1 }$ as an integral. You don't have to solve the integral.
\end{enumerate}
\end{exercise}
